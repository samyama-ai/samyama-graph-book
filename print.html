<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Building Samyama: The Architecture of a Modern Rust Graph Database</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-018e256d.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-348e37c7.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Building Samyama: The Architecture of a Modern Rust Graph Database</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/Madhulatha-Sandeep/samyama-graph" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="preface"><a class="header" href="#preface">Preface</a></h1>
<p>In the rapidly evolving landscape of data systems, we often find ourselves gluing together disparate technologies to build a complete platform. We use Redis for caching, Neo4j for graphs, Qdrant or Pinecone for vectors, and Spark for analytics. This fragmentation leads to “Frankenstein” architectures—complex, fragile, and hard to maintain.</p>
<p><strong>Samyama</strong> (Sanskrit for “Integration” or “Binding together”) was born from a desire to collapse this complexity.</p>
<p>Why can’t a single engine handle the transactional integrity of a graph, the semantic power of vectors, and the raw speed of in-memory analytics? Why must we choose between the flexibility of Cypher and the performance of compiled code?</p>
<p>This book is the story of building <strong>Samyama-Graph</strong>, a modern, high-performance graph database written in Rust. It is not just a user manual; it is an architectural deep dive. We will peel back the layers to show you <em>how</em> it works—from the byte-level serialization in RocksDB to the lock-free concurrency of our MVCC engine, and up to the distributed consensus algorithms that keep it alive.</p>
<h2 id="why-rust"><a class="header" href="#why-rust">Why Rust?</a></h2>
<p>When building a database in the 2020s, the choice of language is pivotal. We chose Rust not just for its hype, but for its promise: <strong>Fearless Concurrency</strong>.</p>
<p>A graph database is, by definition, a pointer-chasing engine. It demands random memory access patterns that are notoriously hard to optimize and easy to mess up (hello, segmentation faults!). Rust’s ownership model allowed us to implement complex memory management strategies—like Arena Allocation and localized reference counting—without the overhead of a Garbage Collector or the safety risks of C++.</p>
<h2 id="who-is-this-book-for"><a class="header" href="#who-is-this-book-for">Who is this book for?</a></h2>
<ul>
<li><strong>System Architects</strong> who want to understand the internals of a modern database.</li>
<li><strong>Rust Developers</strong> curious about real-world patterns for FFI, concurrency, and distributed systems.</li>
<li><strong>Data Engineers</strong> looking for a unified solution for their graph and AI workloads.</li>
</ul>
<p>Let’s begin the journey.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="persistence-at-scale"><a class="header" href="#persistence-at-scale">Persistence at Scale</a></h1>
<p>Every database must answer a fundamental question: <strong>How do we not lose data?</strong></p>
<p>For an in-memory graph database like Samyama, this is doubly critical. While we prioritize speed by keeping the active dataset in RAM, we need a robust, battle-tested persistence layer to ensure durability (the ‘D’ in ACID) and to support datasets larger than memory.</p>
<p>We chose <strong>RocksDB</strong>.</p>
<h2 id="why-rocksdb"><a class="header" href="#why-rocksdb">Why RocksDB?</a></h2>
<p>RocksDB, originally forked from Google’s LevelDB by Facebook, is an embedded key-value store based on a <strong>Log-Structured Merge-Tree (LSM-Tree)</strong>. It is the industry standard for high-performance storage engines, powering systems like CockroachDB, TiKV, and Kafka Streams.</p>
<h3 id="the-lsm-tree-advantage"><a class="header" href="#the-lsm-tree-advantage">The LSM-Tree Advantage</a></h3>
<p>Graph workloads are write-heavy. Creating a single “relationship” between two nodes might involve updating adjacency lists on both ends, updating indices, and writing to the transaction log.</p>
<p>Traditional B-Tree storage (used by Postgres, MySQL) suffers from <strong>Write Amplification</strong>—changing a few bytes can require rewriting entire 4KB or 8KB pages.</p>
<p>LSM-Trees solve this by turning random writes into sequential ones:</p>
<ol>
<li><strong>WAL (Write-Ahead Log)</strong>: Data is appended to a log file for durability.</li>
<li><strong>MemTable</strong>: Data is written to an in-memory sorted structure.</li>
<li><strong>SSTables</strong>: When the MemTable is full, it is flushed to disk as an immutable Sorted String Table.</li>
<li><strong>Compaction</strong>: Background threads merge old SSTables, removing deleted data and optimizing storage.</li>
</ol>
<p>This architecture allows Samyama to sustain ingestion rates of over <strong>800,000 nodes/second</strong>.</p>
<h2 id="schema-design-mapping-graphs-to-key-value"><a class="header" href="#schema-design-mapping-graphs-to-key-value">Schema Design: Mapping Graphs to Key-Value</a></h2>
<p>How do you store a graph (nodes and edges) in a Key-Value store? We use <strong>Column Families</strong> (logical partitions within RocksDB) to separate different types of data.</p>
<h3 id="column-families"><a class="header" href="#column-families">Column Families</a></h3>
<ol>
<li><strong><code>default</code></strong>: Metadata (versioning, configurations).</li>
<li><strong><code>nodes</code></strong>: Stores the actual node data.</li>
<li><strong><code>edges</code></strong>: Stores edge data.</li>
<li><strong><code>indices</code></strong>: Stores property indices (e.g., lookup by name).</li>
</ol>
<h3 id="key-structure"><a class="header" href="#key-structure">Key Structure</a></h3>
<p>We use a simple, efficient binary encoding for keys. All IDs are <code>u64</code> integers.</p>
<ul>
<li><strong>Node Key</strong>: <code>[u8; 8]</code> -&gt; Big-Endian representation of <code>NodeId</code>.</li>
<li><strong>Edge Key</strong>: <code>[u8; 8]</code> -&gt; Big-Endian representation of <code>EdgeId</code>.</li>
</ul>
<h3 id="value-serialization"><a class="header" href="#value-serialization">Value Serialization</a></h3>
<p>For the values (the actual data), we need a format that is compact and fast to deserialize. We chose <strong>Bincode</strong>.</p>
<p>Bincode is a Rust-specific binary serialization format that effectively dumps the memory representation of a struct to disk. It is significantly faster than JSON, Protobuf, or MsgPack for Rust-to-Rust communication.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Serialize, Deserialize)]
struct StoredNode {
    id: u64,
    labels: Vec&lt;String&gt;,
    properties: Vec&lt;u8&gt;, // Compressed property map
    created_at: i64,
    updated_at: i64,
}
<span class="boring">}</span></code></pre>
<h2 id="the-persistence-code"><a class="header" href="#the-persistence-code">The Persistence Code</a></h2>
<p>The integration lives in <code>src/persistence/storage.rs</code>. Here is a simplified view of how we initialize RocksDB with optimal settings for graph workloads:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn open(path: impl AsRef&lt;Path&gt;) -&gt; StorageResult&lt;Self&gt; {
    let mut opts = Options::default();
    opts.create_if_missing(true);
    
    // Performance Tuning
    // 64MB Write Buffer allows larger batches before flushing
    opts.set_write_buffer_size(64 * 1024 * 1024); 
    
    // Use LZ4 compression for speed
    opts.set_compression_type(rocksdb::DBCompressionType::Lz4);

    let cf_descriptors = vec![
        ColumnFamilyDescriptor::new("default", Options::default()),
        ColumnFamilyDescriptor::new("nodes", Self::node_cf_options()),
        ColumnFamilyDescriptor::new("edges", Self::edge_cf_options()),
        ColumnFamilyDescriptor::new("indices", Self::index_cf_options()),
    ];

    let db = DB::open_cf_descriptors(&amp;opts, &amp;path, cf_descriptors)?;
    Ok(Self { db: Arc::new(db), ... })
}
<span class="boring">}</span></code></pre>
<h2 id="durability-vs-performance"><a class="header" href="#durability-vs-performance">Durability vs. Performance</a></h2>
<p>We allow users to configure the <code>sync</code> behavior.</p>
<ul>
<li><strong>Strict Mode</strong>: Every write calls <code>fsync</code>, guaranteeing data is on disk. Slower but safest.</li>
<li><strong>Background Mode</strong>: Writes are acknowledged once in the OS buffer cache. Faster, but risks data loss on power failure (process crash is still safe).</li>
</ul>
<p>In Samyama, we default to a balanced approach: the Raft log (for consensus) is always fsync’d, while the RocksDB state machine catches up asynchronously. This ensures cluster-wide consistency even if a single node fails.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="managing-state-mvcc--memory"><a class="header" href="#managing-state-mvcc--memory">Managing State (MVCC &amp; Memory)</a></h1>
<p>In a high-performance database, “State” is the enemy of speed. Managing it requires locks, and locks kill concurrency.</p>
<p>If User A is reading a graph to calculate the shortest path between two cities, and User B updates a road in the middle of that calculation, what should happen?</p>
<ol>
<li><strong>Locking</strong>: User B waits until User A finishes. (Safe but slow).</li>
<li><strong>Dirty Read</strong>: User A sees the half-updated state and crashes. (Fast but broken).</li>
<li><strong>MVCC</strong>: User A sees the “old” version of the road, while User B writes the “new” version. Both proceed in parallel.</li>
</ol>
<p>Samyama implements <strong>Multi-Version Concurrency Control (MVCC)</strong> using a specialized in-memory structure.</p>
<h2 id="the-data-structure-versioned-arena"><a class="header" href="#the-data-structure-versioned-arena">The Data Structure: Versioned Arena</a></h2>
<p>Most graph databases use pointer-heavy structures (<code>Box&lt;Node&gt;</code>, <code>Rc&lt;RefCell&lt;Node&gt;&gt;</code>). In Rust, this is often a performance trap due to cache misses and borrowing rules.</p>
<p>Samyama uses a <strong>Versioned Arena</strong> pattern.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GraphStore {
    /// Node storage: NodeId -&gt; [Version1, Version2, ...]
    nodes: Vec&lt;Vec&lt;Node&gt;&gt;,
    
    /// Global transaction counter
    pub current_version: u64,
}
<span class="boring">}</span></code></pre>
<h3 id="1-the-id-is-the-index"><a class="header" href="#1-the-id-is-the-index">1. The ID is the Index</a></h3>
<p>A <code>NodeId</code> in Samyama isn’t a random UUID; it’s a direct <code>u64</code> index into the <code>nodes</code> vector. <code>NodeId(5)</code> means “look at index 5 in the vector”. This gives us <strong>O(1)</strong> access time without hashing.</p>
<h3 id="2-the-version-chain"><a class="header" href="#2-the-version-chain">2. The Version Chain</a></h3>
<p>The inner vector <code>Vec&lt;Node&gt;</code> represents the history of that node.</p>
<ul>
<li>Index 0: The oldest version.</li>
<li>Index N: The latest version.</li>
</ul>
<p>When a write happens:</p>
<ol>
<li>We acquire a write lock on the specific node (or the whole structure, depending on the transaction scope).</li>
<li>We <strong>clone</strong> the latest version.</li>
<li>We apply the changes to the clone.</li>
<li>We push the new version to the end of the list with <code>version = current_global_version + 1</code>.</li>
</ol>
<h2 id="snapshot-isolation"><a class="header" href="#snapshot-isolation">Snapshot Isolation</a></h2>
<p>This structure enables <strong>Snapshot Isolation</strong>. When a query starts, it grabs the <code>current_version</code> (say, 100).</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified logic
fn get_node_at_version(&amp;self, id: NodeId, query_version: u64) -&gt; Option&lt;&amp;Node&gt; {
    let history = &amp;self.nodes[id];
    
    // Iterate backwards to find the newest version &lt;= query_version
    for node_version in history.iter().rev() {
        if node_version.version &lt;= query_version {
            return Some(node_version);
        }
    }
    None
}
<span class="boring">}</span></code></pre>
<p>Even if a writer updates the node to version 101, 102, and 103 while the query is running, the query logic will simply skip them and return version 100.</p>
<h2 id="memory-management--cleanup"><a class="header" href="#memory-management--cleanup">Memory Management &amp; cleanup</a></h2>
<p>“But wait,” you ask, “won’t memory explode if you keep every version forever?”</p>
<p>Yes. That’s why we have <strong>Garbage Collection (GC)</strong>.
Samyama runs a background process that “prunes” versions that are:</p>
<ol>
<li>Older than the oldest active transaction.</li>
<li>Persisted to RocksDB (for cold storage).</li>
</ol>
<p>This architecture allows Samyama to serve heavy analytical queries (which might take seconds) simultaneously with high-throughput transactional writes (thousands per second) without them blocking each other.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="technology-choices-the-why"><a class="header" href="#technology-choices-the-why">Technology Choices (The “Why”)</a></h1>
<p>Building a database is an exercise in trade-offs. In this chapter, we explore the specific technology choices that define Samyama and why we chose them over popular alternatives.</p>
<h2 id="rust-vs-the-world"><a class="header" href="#rust-vs-the-world">Rust vs. The World</a></h2>
<p>Why not C++? Why not Go?</p>
<p>As documented in our internal benchmarks, Rust provides a unique combination of <strong>Memory Safety</strong> and <strong>Zero-Cost Abstractions</strong>.</p>
<h3 id="the-performance-gap"><a class="header" href="#the-performance-gap">The Performance Gap</a></h3>
<p>In a 2-hop traversal benchmark on 1 million nodes:</p>
<ul>
<li><strong>Rust</strong>: 12ms (with 450MB RAM)</li>
<li><strong>Go</strong>: 45ms (with 850MB RAM + GC Pauses)</li>
<li><strong>Java</strong>: 38ms (with 1200MB RAM + GC Pauses)</li>
</ul>
<p>The “Cautionary Tale of InfluxDB” served as a warning to us. Originally written in Go, the InfluxDB team eventually rewrote their core query engine in Rust to eliminate unpredictable garbage collection pauses that were impacting P99 latencies. We chose to start with Rust to avoid that “technical debt” from day one.</p>
<h2 id="rocksdb-vs-b-trees"><a class="header" href="#rocksdb-vs-b-trees">RocksDB vs. B-Trees</a></h2>
<p>We chose an <strong>LSM-Tree</strong> (RocksDB) over a <strong>B-Tree</strong> (LMDB).</p>
<p>Graph workloads are naturally write-heavy—every relationship creation involves multiple index updates. B-Trees suffer from “Write Amplification,” where changing a few bytes requires rewriting entire pages. RocksDB turns these random writes into sequential appends, allowing Samyama to sustain over <strong>350,000 node writes per second</strong>, significantly outperforming LMDB in write-heavy scenarios.</p>
<h2 id="zero-copy-serialization"><a class="header" href="#zero-copy-serialization">Zero-Copy Serialization</a></h2>
<p>Traditional serialization (JSON, Protobuf) requires “deserializing” data into memory objects before they can be used. This is a massive overhead for a database.</p>
<p>Samyama uses <strong>Cap’n Proto</strong> and <strong>Apache Arrow</strong>.</p>
<ul>
<li><strong>Cap’n Proto</strong>: Provides true zero-copy access. We cast a pointer to a memory-mapped file directly into a Rust struct. Deserialization time is effectively <strong>0μs</strong>.</li>
<li><strong>Apache Arrow</strong>: Used for property storage. By storing properties in a columnar format (all “ages” together, all “salaries” together), we enable SIMD instructions to process multiple values in a single CPU cycle.</li>
</ul>
<h2 id="tokio-the-async-heart"><a class="header" href="#tokio-the-async-heart">Tokio: The Async Heart</a></h2>
<p>Concurrency in Samyama is managed by <strong>Tokio</strong>, a work-stealing async runtime.
Unlike “thread-per-core” models (like Glommio), Tokio’s work-stealing approach prevents “starvation”—if one thread is stuck on a heavy calculation, other threads can “steal” tasks from its queue to keep the CPU utilized at 100%. This is critical for handling thousands of concurrent query connections without a massive increase in latency.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-query-engine"><a class="header" href="#the-query-engine">The Query Engine</a></h1>
<p>The heart of any database is its query engine. It translates the user’s intent (expressed in a query language) into actionable operations on the data.</p>
<p>Samyama supports <strong>OpenCypher</strong>, the most widely adopted graph query language.</p>
<h2 id="from-string-to-plan"><a class="header" href="#from-string-to-plan">From String to Plan</a></h2>
<p>When a user sends a query like:</p>
<pre><code class="language-cypher">MATCH (p:Person)-[:KNOWS]-&gt;(f:Person)
WHERE p.age &gt; 30
RETURN f.name
</code></pre>
<p>It goes through three distinct stages:</p>
<h3 id="1-parsing-the-pest-parser"><a class="header" href="#1-parsing-the-pest-parser">1. Parsing (The <code>pest</code> Parser)</a></h3>
<p>We use <code>pest</code>, a PEG (Parsing Expression Grammar) parser generator for Rust. The grammar is defined in <code>cypher.pest</code>.
The output is an Abstract Syntax Tree (AST) representing the query structure.</p>
<h3 id="2-logical-planning"><a class="header" href="#2-logical-planning">2. Logical Planning</a></h3>
<p>The AST is converted into a <strong>Logical Plan</strong>. This is a tree of high-level operators like <code>Scan</code>, <code>Filter</code>, <code>Join</code>, and <code>Project</code>. At this stage, the engine doesn’t care <em>how</em> the data is stored, only <em>what</em> needs to be done.</p>
<h3 id="3-physical-planning"><a class="header" href="#3-physical-planning">3. Physical Planning</a></h3>
<p>The optimizer transforms the Logical Plan into a <strong>Physical Plan</strong>. This involves:</p>
<ul>
<li>Choosing index scans over full scans.</li>
<li>Reordering joins for efficiency.</li>
<li>Selecting specific algorithms (e.g., <code>HashJoin</code> vs <code>NestedLoopJoin</code>).</li>
</ul>
<p><img src="images/architecture.svg" alt="Samyama Architecture"></p>
<h2 id="execution-model-volcano-vs-vectorization"><a class="header" href="#execution-model-volcano-vs-vectorization">Execution Model: Volcano vs. Vectorization</a></h2>
<p>Samyama implements a hybrid execution model.</p>
<h3 id="the-volcano-model-iterator"><a class="header" href="#the-volcano-model-iterator">The Volcano Model (Iterator)</a></h3>
<p>Historically, databases used the “Volcano” model. Each operator implements a <code>next()</code> method that returns a single tuple (or <code>Record</code>).</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait PhysicalOperator {
    fn next(&amp;mut self, store: &amp;GraphStore) -&gt; Option&lt;Record&gt;;
}
<span class="boring">}</span></code></pre>
<ul>
<li><strong>Pros</strong>: Simple, composable, low memory footprint.</li>
<li><strong>Cons</strong>: High CPU overhead due to virtual function calls per row.</li>
</ul>
<h3 id="vectorized-execution-the-samyama-way"><a class="header" href="#vectorized-execution-the-samyama-way">Vectorized Execution (The Samyama Way)</a></h3>
<p>To achieve modern performance, especially for analytical workloads, Samyama implements <strong>Vectorized Execution</strong>. Instead of processing one row at a time, operators process <strong>batches</strong> (typically 1024 rows).</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait PhysicalOperator {
    // Classic fallback
    fn next(&amp;mut self, store: &amp;GraphStore) -&gt; Option&lt;Record&gt;;

    // High-performance batch path
    fn next_batch(&amp;mut self, store: &amp;GraphStore, batch_size: usize) -&gt; Option&lt;RecordBatch&gt;;
}
<span class="boring">}</span></code></pre>
<p>The <code>RecordBatch</code> utilizes Columnar storage principles (similar to Apache Arrow) where possible, allowing the CPU to use SIMD (Single Instruction, Multiple Data) instructions to process data faster.</p>
<p>For example, the <code>NodeScanOperator</code> in Samyama retrieves a block of 1024 <code>NodeId</code>s at once, rather than iterating one by one. This reduces the instruction cache misses and function call overhead by nearly 3 orders of magnitude.</p>
<h2 id="the-operator-library"><a class="header" href="#the-operator-library">The Operator Library</a></h2>
<p>Samyama includes a rich library of physical operators:</p>
<ul>
<li><strong><code>NodeScan</code></strong>: Scans all nodes or uses a Label index.</li>
<li><strong><code>IndexScan</code></strong>: Uses a B-Tree property index for fast lookups (e.g., <code>WHERE n.id = 1</code>).</li>
<li><strong><code>VectorSearch</code></strong>: A specialized operator that queries the HNSW index for semantic similarity.</li>
<li><strong><code>Expand</code></strong>: The core graph traversal operator. It takes a node and “expands” it to its neighbors via the adjacency list.</li>
<li><strong><code>Filter</code></strong>: Applies boolean logic to batches.</li>
<li><strong><code>Project</code></strong>: Selects and renames fields.</li>
<li><strong><code>Aggregate</code></strong>: Performs <code>GROUP BY</code>, <code>COUNT</code>, <code>SUM</code>, etc.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="analytical-power-csr--algorithms"><a class="header" href="#analytical-power-csr--algorithms">Analytical Power (CSR &amp; Algorithms)</a></h1>
<p>Transactional queries (OLTP) usually touch a small subgraph: “Find Alice’s friends.”
Analytical queries (OLAP) touch the <em>entire</em> graph: “Rank every webpage by importance (PageRank).”</p>
<p>The pointer-chasing structure of a standard graph database (Adjacency Lists) is excellent for OLTP but suboptimal for OLAP due to cache misses.</p>
<p>Samyama solves this by introducing a dedicated <strong>Analytics Engine</strong> in the <code>samyama-graph-algorithms</code> crate.</p>
<h2 id="the-csr-compressed-sparse-row-format"><a class="header" href="#the-csr-compressed-sparse-row-format">The CSR (Compressed Sparse Row) Format</a></h2>
<p>When you run an algorithm like PageRank or Betweenness Centrality, Samyama doesn’t run it directly on the <code>GraphStore</code>. Instead, it projects the relevant subgraph into a highly optimized read-only structure called <strong>CSR</strong>.</p>
<p>A Graph $G=(V, E)$ is represented by three contiguous arrays:</p>
<ol>
<li><strong><code>out_offsets</code></strong>: Indices indicating where each node’s neighbor list starts.</li>
<li><strong><code>out_targets</code></strong>: A massive, flat array of all neighbor IDs.</li>
<li><strong><code>weights</code></strong>: (Optional) Edge weights corresponding to <code>out_targets</code>.</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GraphView {
    pub out_offsets: Vec&lt;usize&gt;,
    pub out_targets: Vec&lt;usize&gt;,
    // ...
}
<span class="boring">}</span></code></pre>
<h3 id="why-csr"><a class="header" href="#why-csr">Why CSR?</a></h3>
<ul>
<li><strong>Memory Compactness</strong>: No overhead for pointers or objects. Just raw integers.</li>
<li><strong>Cache Locality</strong>: Iterating neighbors is a sequential memory read, which CPUs love. PREFETCH instructions work perfectly here.</li>
<li><strong>Parallelism</strong>: Since the structure is read-only, we can safely share it across Rayon threads without locks.</li>
</ul>
<h2 id="the-algorithm-library"><a class="header" href="#the-algorithm-library">The Algorithm Library</a></h2>
<p>We have implemented standard graph algorithms optimized for this structure:</p>
<ol>
<li>
<p><strong>Centrality</strong>:</p>
<ul>
<li><strong>PageRank</strong>: The classic algorithm for node importance.</li>
<li><strong>Eigenvector Centrality</strong>: Similar to PageRank but for undirected graphs.</li>
</ul>
</li>
<li>
<p><strong>Community Detection</strong>:</p>
<ul>
<li><strong>Weakly Connected Components (WCC)</strong>: Finds isolated islands in the graph.</li>
<li><strong>Louvain / Leiden</strong>: (Planned) For detecting dense clusters.</li>
</ul>
</li>
<li>
<p><strong>Pathfinding</strong>:</p>
<ul>
<li><strong>BFS / DFS</strong>: Standard traversals.</li>
<li><strong>Dijkstra / A*</strong>: Shortest weighted paths.</li>
<li><strong>Delta-Stepping</strong>: A parallelized version of Dijkstra for large graphs.</li>
</ul>
</li>
</ol>
<h2 id="python-bindings-data-science-integration"><a class="header" href="#python-bindings-data-science-integration">Python Bindings: Data Science Integration</a></h2>
<p>We know that data scientists live in Python. We use <strong>PyO3</strong> to expose these Rust-optimized algorithms directly to Python.</p>
<p>The <code>GraphView</code> is zero-copy shared with Python where possible, or efficiently constructed.</p>
<pre><code class="language-python">import samyama

# Connect to the DB
db = samyama.connect("localhost:6379")

# Run PageRank on the "Person" subgraph connected by "KNOWS"
# This runs in Rust at C++ speeds, but is called from Python!
scores = db.algo.page_rank(
    label="Person", 
    relationship="KNOWS", 
    damping_factor=0.85
)
</code></pre>
<p>This architecture allows Samyama to replace dedicated graph analytics frameworks like NetworkX (which is slow) or GraphFrames (which requires Spark), providing a single engine for storage and analysis.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="predictive-power-gnns"><a class="header" href="#predictive-power-gnns">Predictive Power (GNNs)</a></h1>
<p>While traditional graph algorithms like PageRank tell you about the <em>importance</em> of a node, <strong>Graph Neural Networks (GNNs)</strong> allow the database to make <em>predictions</em> about the future.</p>
<p>Samyama’s philosophy on GNNs is clear: <strong>We focus on Inference, not Training.</strong></p>
<h2 id="the-problem-data-gravity"><a class="header" href="#the-problem-data-gravity">The Problem: Data Gravity</a></h2>
<p>Training a GNN model (using frameworks like PyTorch Geometric or DGL) requires massive compute power and specialized hardware. However, once a model is trained, moving the entire graph to a Python environment every time you need a prediction is slow and expensive. This is “Data Gravity.”</p>
<h2 id="the-solution-in-database-inference"><a class="header" href="#the-solution-in-database-inference">The Solution: In-Database Inference</a></h2>
<p>Samyama implements an inference engine based on <strong>ONNX Runtime</strong> (<code>ort</code>).</p>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How it works:</a></h3>
<ol>
<li><strong>Export</strong>: You train your GNN in Python (where the data science ecosystem is best) and export it to the standard <strong>ONNX</strong> format.</li>
<li><strong>Upload</strong>: You upload the model to Samyama.</li>
<li><strong>Execute</strong>: You run predictions directly in your Cypher queries.</li>
</ol>
<pre><code class="language-cypher">// Predict the fraud risk for a person based on their connections
CALL algo.gnn.predict('fraud_model_v1', 'Person') 
YIELD node, score
SET node.fraud_score = score
</code></pre>
<h2 id="graphsage-aggregators"><a class="header" href="#graphsage-aggregators">GraphSAGE Aggregators</a></h2>
<p>For users who want “Zero-Config” intelligence, we have implemented native <strong>GraphSAGE-style Aggregators</strong>.</p>
<p>Instead of an external model, these aggregators leverage the existing <strong>Vector Search (HNSW)</strong> infrastructure. They compute a new node embedding by aggregating the vectors of its neighbors (mean, max, or LSTM pooling).</p>
<p>This allows the database to act as a <strong>Dynamic Feature Store</strong>, where embeddings are updated in real-time as the graph evolves, providing a predictive layer that most graph databases lack.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="in-database-optimization-metaheuristics"><a class="header" href="#in-database-optimization-metaheuristics">In-Database Optimization (Metaheuristics)</a></h1>
<p>Most graph databases stop at “Retrieval.” They help you find data. Samyama goes a step further into <strong>Prescription</strong>.</p>
<p>By integrating a suite of 15+ metaheuristic solvers directly into the engine via the <code>samyama-optimization</code> crate, we allow users to solve complex Operation Research (OR) problems where the graph <em>is</em> the model.</p>
<h2 id="what-are-metaheuristics"><a class="header" href="#what-are-metaheuristics">What are Metaheuristics?</a></h2>
<p>Unlike exact solvers (like CPLEX), metaheuristics are nature-inspired algorithms that search for “good enough” solutions in massive, complex search spaces where an exact answer is mathematically impossible to find in a reasonable time.</p>
<p>Samyama supports three main families:</p>
<ol>
<li><strong>Metaphor-less</strong>: <strong>Jaya</strong>, <strong>Rao (1, 2, 3)</strong>, and <strong>TLBO</strong>. These are high-performance algorithms with very few parameters to tune.</li>
<li><strong>Nature-Inspired</strong>: <strong>Grey Wolf Optimizer (GWO)</strong>, <strong>Particle Swarm (PSO)</strong>, <strong>Firefly</strong>, and <strong>Cuckoo Search</strong>.</li>
<li><strong>Multi-Objective</strong>: <strong>NSGA-II</strong> and <strong>MOTLBO</strong> for solving problems with conflicting goals (e.g., “Minimize Cost” vs. “Maximize Safety”).</li>
</ol>
<p><img src="images/pareto_front.svg" alt="Pareto Front"></p>
<h2 id="the-graph-to-optimization-bridge"><a class="header" href="#the-graph-to-optimization-bridge">The Graph-to-Optimization Bridge</a></h2>
<p>Samyama allows you to define an optimization problem using Cypher. The database maps node properties to decision variables and edges to constraints.</p>
<pre><code class="language-cypher">// Optimize Factory production to minimize cost
CALL algo.or.solve({
  algorithm: 'Jaya',
  label: 'Factory',
  property: 'production_rate',
  min: 10.0,
  max: 100.0,
  cost_property: 'unit_cost',
  budget: 50000.0
}) 
YIELD fitness, variables
</code></pre>
<h2 id="parallel-evolution"><a class="header" href="#parallel-evolution">Parallel Evolution</a></h2>
<p>Optimization is computationally expensive. Samyama’s engine evaluates entire “populations” of candidate solutions in parallel using <strong>Rayon</strong>. If you have a 32-core server, Samyama will evolve 32 potential solutions simultaneously, finding the optimal resource allocation in milliseconds where a Python-based solver would take seconds.</p>
<p>This unique integration makes Samyama the ideal choice for <strong>Smart Manufacturing</strong>, <strong>Logistics</strong>, and <strong>Healthcare Management</strong>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="distributed-consensus--sharding"><a class="header" href="#distributed-consensus--sharding">Distributed Consensus &amp; Sharding</a></h1>
<p>A single node can only go so far. To scale beyond a single machine’s memory and CPU, Samyama employs a distributed architecture built on the Raft consensus algorithm.</p>
<h2 id="consistency-via-raft"><a class="header" href="#consistency-via-raft">Consistency via Raft</a></h2>
<p>We use the <code>openraft</code> crate, a modern, asynchronous implementation of the Raft protocol.</p>
<p>Raft provides <strong>Strong Consistency</strong> by ensuring that a cluster of nodes agrees on the order of operations (the Log) before applying them to the state machine (the Graph).</p>
<h3 id="the-raft-loop"><a class="header" href="#the-raft-loop">The Raft Loop</a></h3>
<ol>
<li><strong>Leader Election</strong>: Nodes elect a Leader.</li>
<li><strong>Log Replication</strong>: All write requests go to the Leader. The Leader appends the request to its log and sends it to Followers.</li>
<li><strong>Commit</strong>: Once a majority (Quorum) acknowledges the log entry, the Leader commits it.</li>
<li><strong>Apply</strong>: The committed entry is applied to the <code>GraphStore</code>.</li>
</ol>
<p>This ensures that if a client receives an “OK” response, the data is durable on at least $N/2 + 1$ nodes.</p>
<h2 id="sharding-strategy"><a class="header" href="#sharding-strategy">Sharding Strategy</a></h2>
<p>Samyama implements <strong>Tenant-Level Sharding</strong>.</p>
<p>In a multi-tenant environment (e.g., a SaaS platform serving many companies), data from different tenants is naturally isolated.</p>
<ul>
<li><strong>Shard</strong>: A logical partition of the data.</li>
<li><strong>Routing</strong>: The <code>Router</code> component (<code>src/sharding/router.rs</code>) maps a <code>TenantId</code> to a specific Raft Cluster (Shard).</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified Routing Logic
pub fn route(&amp;self, tenant_id: &amp;str) -&gt; ClusterId {
    let hash = seahash::hash(tenant_id.as_bytes());
    hash % self.num_shards
}
<span class="boring">}</span></code></pre>
<p>This approach avoids the complexity of distributed graph partitioning (cutting edges across machines) while offering infinite horizontal scale for multi-tenant workloads.</p>
<h3 id="future-graph-partitioning"><a class="header" href="#future-graph-partitioning">Future: Graph Partitioning</a></h3>
<p>For single-tenant graphs that exceed one machine, we are researching “Graph-Aware Partitioning” using METIS, but for now, Tenant Sharding is the production-ready strategy.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="ai--vector-search"><a class="header" href="#ai--vector-search">AI &amp; Vector Search</a></h1>
<p>The “Vector Database” hype train has led to many specialized tools (Pinecone, Weaviate). But a vector is just a property of a node. Separating vectors from the graph creates data silos.</p>
<p>Samyama treats Vectors as <strong>First-Class Citizens</strong>.</p>
<h2 id="the-hnsw-index"><a class="header" href="#the-hnsw-index">The HNSW Index</a></h2>
<p>We use the <strong>Hierarchical Navigable Small World (HNSW)</strong> algorithm (via the <code>hnsw_rs</code> crate) to index high-dimensional vectors.</p>
<ul>
<li><strong>Storage</strong>: Vectors are stored in a dedicated RocksDB column family.</li>
<li><strong>Indexing</strong>: The HNSW graph is maintained in memory for millisecond-speed nearest neighbor search.</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct VectorIndex {
    dimensions: usize,
    metric: DistanceMetric, // Cosine, L2, or DotProduct
    hnsw: Hnsw&lt;'static, f32, CosineDistance&gt;,
}
<span class="boring">}</span></code></pre>
<h2 id="graph-rag-retrieval-augmented-generation"><a class="header" href="#graph-rag-retrieval-augmented-generation">Graph RAG (Retrieval Augmented Generation)</a></h2>
<p>The power of Samyama comes from combining Vector Search with Graph Traversal in a single query.</p>
<p><strong>Scenario</strong>: You want to find legal precedents that are <em>semantically similar</em> to a case file AND <em>cited by</em> a specific judge.</p>
<p>Pure Vector DB:</p>
<ol>
<li>Query Vector DB -&gt; Get top 100 docs.</li>
<li>Filter in application -&gt; Keep only those cited by Judge X.</li>
<li>Problem: You might filter out all 100 docs!</li>
</ol>
<p>Samyama (Graph RAG):</p>
<pre><code class="language-cypher">// 1. Vector Search finds the entry points
CALL db.index.vector.queryNodes('Precedent', 'embedding', $query_vector, 100)
YIELD node, score

// 2. Graph Pattern filters them immediately
MATCH (node)&lt;-[:CITED]-(j:Judge {name: 'Scalia'})

// 3. Return best matches
RETURN node.summary, score
ORDER BY score DESC LIMIT 5
</code></pre>
<p>This “Pre-filtering” or “Post-filtering” happens inside the engine, enabling highly efficient Retrieval-Augmented Generation workflows for LLMs.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="agentic-enrichment"><a class="header" href="#agentic-enrichment">Agentic Enrichment</a></h1>
<p>Traditional databases are passive. They store what you give them. If you ask a question and the data isn’t there, you get an empty result.</p>
<p>Samyama introduces <strong>Agentic Enrichment</strong>—a paradigm shift where the database becomes an active participant in building its own knowledge.</p>
<h2 id="from-rag-to-gak"><a class="header" href="#from-rag-to-gak">From RAG to GAK</a></h2>
<p>We are all familiar with <strong>Retrieval-Augmented Generation (RAG)</strong>: using a database to help an LLM.
Samyama implements <strong>Generation-Augmented Knowledge (GAK)</strong>: using an LLM to help build the database.</p>
<h2 id="the-autonomous-enrichment-loop"><a class="header" href="#the-autonomous-enrichment-loop">The Autonomous Enrichment Loop</a></h2>
<p>Samyama can be configured with <strong>Enrichment Policies</strong>. When a new node is created or a specific property is queried, an autonomous agent can “wake up” to fill in the gaps.</p>
<p><img src="images/agentic_loop.svg" alt="Agentic Loop"></p>
<h3 id="example-the-research-assistant"><a class="header" href="#example-the-research-assistant">Example: The Research Assistant</a></h3>
<p>Imagine you are building a medical knowledge graph. You create a node for a new drug, <code>Semaglutide</code>.</p>
<p><strong>The Passive Way</strong>: You manually search PubMed, find papers, and insert them.
<strong>The Samyama Way</strong>:</p>
<ol>
<li>You create the <code>Drug</code> node.</li>
<li>An <strong>Event Trigger</strong> fires an Enrichment Agent.</li>
<li>The Agent uses a <strong>Web Search Tool</strong> to find recent clinical trials.</li>
<li>The Agent parses the results into JSON.</li>
<li>The database automatically executes <code>CREATE</code> commands to link the new papers to the <code>Drug</code> node.</li>
</ol>
<h2 id="just-in-time-jit-knowledge-graphs"><a class="header" href="#just-in-time-jit-knowledge-graphs">Just-In-Time (JIT) Knowledge Graphs</a></h2>
<p>This enables what we call a <strong>JIT Knowledge Graph</strong>. The graph doesn’t need to be complete on day one. It grows and “heals” itself based on user interaction.</p>
<p>If a user asks: <em>“How does the current Fed interest rate impact my mortgage?”</em> and the <code>Fed Rate</code> node is missing, the database can fetch the live rate, create the node, and then answer the question.</p>
<p>By integrating LLMs directly into the write pipeline, Samyama transforms from a simple storage engine into a dynamic, self-evolving brain.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="observability--multi-tenancy"><a class="header" href="#observability--multi-tenancy">Observability &amp; Multi-tenancy</a></h1>
<p>A database in production is a living organism. To keep it healthy, we need to see inside it, and to keep it secure, we need to isolate its users.</p>
<h2 id="multi-tenancy-namespace-isolation"><a class="header" href="#multi-tenancy-namespace-isolation">Multi-tenancy: Namespace Isolation</a></h2>
<p>Samyama is “Multi-tenant by Design.” We don’t just put everyone’s data in one big bucket; we use <strong>Namespace Isolation</strong>.</p>
<h3 id="logical-separation-with-rocksdb"><a class="header" href="#logical-separation-with-rocksdb">Logical Separation with RocksDB</a></h3>
<p>We leverage RocksDB’s <strong>Column Families</strong> (CF) for this. Each tenant is assigned their own CF.</p>
<ul>
<li><strong>Isolation</strong>: Tenant A’s keyspace is physically and logically distinct from Tenant B’s.</li>
<li><strong>Maintenance</strong>: Compaction (the background cleanup process) happens per-tenant. If Tenant A is doing heavy writes, it won’t trigger a slow compaction for Tenant B.</li>
<li><strong>Backup</strong>: We can snapshot and restore individual tenants without affecting others.</li>
</ul>
<h3 id="resource-quotas"><a class="header" href="#resource-quotas">Resource Quotas</a></h3>
<p>To prevent the “Noisy Neighbor” problem, Samyama enforces strict resource quotas per tenant:</p>
<ul>
<li><strong>Memory Quota</strong>: Max RAM for the in-memory graph.</li>
<li><strong>Storage Quota</strong>: Max disk space in RocksDB.</li>
<li><strong>Query Time</strong>: Max duration for a single Cypher query (to prevent “queries from hell” from locking the CPU).</li>
</ul>
<h2 id="observability-the-three-pillars"><a class="header" href="#observability-the-three-pillars">Observability: The Three Pillars</a></h2>
<p>We follow the industry-standard observability stack: <strong>Prometheus</strong>, <strong>OpenTelemetry (OTEL)</strong>, and <strong>Structured Logging</strong>.</p>
<h3 id="1-metrics-prometheus"><a class="header" href="#1-metrics-prometheus">1. Metrics (Prometheus)</a></h3>
<p>Samyama exports hundreds of metrics in the Prometheus format.</p>
<ul>
<li><strong>QPS</strong>: Queries per second (Read vs. Write).</li>
<li><strong>Latency Histograms</strong>: P50, P95, and P99 response times.</li>
<li><strong>Cache Hit Rates</strong>: How often we are hitting the in-memory graph versus going to RocksDB.</li>
</ul>
<h3 id="2-tracing-opentelemetry"><a class="header" href="#2-tracing-opentelemetry">2. Tracing (OpenTelemetry)</a></h3>
<p>For complex, distributed queries, metrics aren’t enough. We need to know <em>where</em> the time was spent.
Using the <code>tracing</code> crate in Rust, we generate distributed traces that can be visualized in <strong>Jaeger</strong> or <strong>Grafana Tempo</strong>. You can see exactly how many milliseconds were spent parsing the query, planning it, and executing it on different nodes in the cluster.</p>
<h3 id="3-structured-logging"><a class="header" href="#3-structured-logging">3. Structured Logging</a></h3>
<p>Gone are the days of parsing text logs. Samyama emits <strong>JSON logs</strong>.</p>
<pre><code class="language-json">{
  "timestamp": "2026-02-08T10:30:45Z",
  "level": "INFO",
  "query": "MATCH (n) RETURN n",
  "duration_ms": 12,
  "tenant": "acme_corp"
}
</code></pre>
<p>This allows for easy ingestion into ELK (Elasticsearch, Logstash, Kibana) or Loki for powerful log aggregation and searching.</p>
<p>By combining strong tenant isolation with deep observability, Samyama provides an “Enterprise-Ready” experience that allows operators to run massive multi-user clusters with confidence.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="performance--benchmarks"><a class="header" href="#performance--benchmarks">Performance &amp; Benchmarks</a></h1>
<p>Samyama is designed for “Mechanical Sympathy”—aligning the software’s data structures with the physical reality of modern CPU caches and SSDs.</p>
<h2 id="the-v050-benchmark-suite"><a class="header" href="#the-v050-benchmark-suite">The v0.5.0 Benchmark Suite</a></h2>
<p>After implementing CSR, Vectorized Execution, and Columnar Storage, we achieved the following results on commodity hardware:</p>
<h3 id="ingestion-the-write-story"><a class="header" href="#ingestion-the-write-story">Ingestion (The “Write” Story)</a></h3>
<ul>
<li><strong>Nodes</strong>: 363,000 / sec</li>
<li><strong>Edges</strong>: 1.51 Million / sec</li>
</ul>
<p>This high throughput is achieved by decoupling the write path. Writes are acknowledged once they hit the <strong>Write-Ahead Log (WAL)</strong>, while indexing (B-Tree and HNSW) happens asynchronously in background threads.</p>
<h3 id="vector-search-the-ai-story"><a class="header" href="#vector-search-the-ai-story">Vector Search (The “AI” Story)</a></h3>
<ul>
<li><strong>Latency</strong>: 1.33ms (Avg)</li>
<li><strong>Throughput</strong>: 752 Queries Per Second</li>
<li><strong>Accuracy</strong>: 98% recall on 10k vectors</li>
</ul>
<p>By using the <strong>HNSW</strong> algorithm, we provide semantic search capabilities that are as fast as a traditional property lookup.</p>
<h2 id="the-power-of-late-materialization"><a class="header" href="#the-power-of-late-materialization">The Power of Late Materialization</a></h2>
<p>One of the biggest performance wins in Samyama was the transition to <strong>Late Materialization</strong>.</p>
<p>In early versions, our query engine would “hydrate” a full <code>Node</code> object (cloning all its properties) as soon as it was matched. In a 2-hop traversal, this led to massive memory allocation and CPU cycles spent cloning data that might never be returned.</p>
<p><strong>The Fix</strong>:
Operators now pass around lightweight <code>NodeRef</code>s (just a <code>u64</code> ID). We only “materialize” the properties at the very last step (the <code>RETURN</code> clause) or when they are explicitly needed for a <code>WHERE</code> filter.</p>
<p><strong>The Impact</strong>:</p>
<ul>
<li><strong>1-Hop Query</strong>: 164ms → 41ms (<strong>4x faster</strong>)</li>
<li><strong>2-Hop Query</strong>: 1.22s → 259ms (<strong>4.7x faster</strong>)</li>
</ul>
<h2 id="the-last-bottleneck-parsing"><a class="header" href="#the-last-bottleneck-parsing">The Last Bottleneck: Parsing</a></h2>
<p>As shown in our profiling, the <strong>Execution</strong> of a query now takes less than <strong>1ms</strong>. The remaining ~40ms is spent in the <strong>Parser</strong> and <strong>Planner</strong>.</p>
<p>Our next architectural step is <strong>Query AST Caching</strong>. By caching the results of the <code>pest</code> parser, we expect to bring the total latency of repeated queries down to <strong>~15ms</strong>, making Samyama one of the fastest graph engines in the industry.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="real-world-use-cases"><a class="header" href="#real-world-use-cases">Real-world Use Cases</a></h1>
<p>Samyama is not just a research project; it is designed to solve complex, real-world problems. We include several fully functional demos in the <code>examples/</code> directory of the repository.</p>
<p>Here are three key scenarios where Samyama shines.</p>
<h2 id="1-banking-fraud-detection"><a class="header" href="#1-banking-fraud-detection">1. Banking: Fraud Detection</a></h2>
<p><strong>Source</strong>: <code>examples/banking_demo.rs</code></p>
<p>Financial fraud often involves complex networks of transactions that traditional SQL databases struggle to uncover.</p>
<p><strong>The Scenario</strong>: A money laundering ring moves illicit funds through a series of “mule” accounts to hide the origin, eventually depositing it back into a clean account. This creates a cycle.</p>
<p><strong>The Solution</strong>:
We model the data as:</p>
<ul>
<li><strong>Nodes</strong>: <code>Account</code></li>
<li><strong>Edges</strong>: <code>TRANSFER</code> (with properties <code>amount</code>, <code>date</code>)</li>
</ul>
<p><strong>The Query</strong>:</p>
<pre><code class="language-cypher">MATCH (a:Account)-[t1:TRANSFER]-&gt;(b:Account)-[t2:TRANSFER]-&gt;(c:Account)-[t3:TRANSFER]-&gt;(a)
WHERE t1.amount &gt; 10000 
  AND t2.amount &gt; 9000 
  AND t3.amount &gt; 8000
RETURN a.id, b.id, c.id
</code></pre>
<p>This simple query instantly reveals circular transaction patterns that would require massive, slow <code>JOIN</code>s in SQL.</p>
<h2 id="2-supply-chain-dependency-analysis"><a class="header" href="#2-supply-chain-dependency-analysis">2. Supply Chain: Dependency Analysis</a></h2>
<p><strong>Source</strong>: <code>examples/supply_chain_demo.rs</code></p>
<p>Modern supply chains are fragile. Knowing “who supplies my supplier” is critical for risk management.</p>
<p><strong>The Scenario</strong>: A factory produces a “Car”. It needs an “Engine”, which needs “Pistons”, which needs “Steel”. If a strike hits the Steel mill, how does it affect Car production?</p>
<p><strong>The Solution</strong>:
We use the <strong>Graph Algorithms</strong> module (specifically Breadth-First Search or custom traversal).</p>
<p><strong>The Logic</strong>:</p>
<ol>
<li>Start at the “Steel Mill” node.</li>
<li>Traverse all outgoing <code>SUPPLIES</code> edges recursively.</li>
<li>Identify all downstream <code>Factory</code> nodes.</li>
<li>Calculate the “Risk Score” based on the dependency depth.</li>
</ol>
<h2 id="3-knowledge-graph-clinical-trials"><a class="header" href="#3-knowledge-graph-clinical-trials">3. Knowledge Graph: Clinical Trials</a></h2>
<p><strong>Source</strong>: <code>examples/clinical_trials_demo.rs</code> + <code>examples/graph_rag_demo.rs</code></p>
<p>Medical research is unstructured. Trials, drugs, and conditions are buried in text documents.</p>
<p><strong>The Scenario</strong>: A researcher wants to find “Drugs used for Hypertension that have a mechanism similar to ACE inhibitors.”</p>
<p><strong>The Solution (Graph RAG)</strong>:</p>
<ol>
<li><strong>Ingest</strong>: Load ClinicalTrials.gov data into Samyama.</li>
<li><strong>Embed</strong>: Use the “Auto-Embed” pipeline to turn the “Mechanism of Action” text into vectors.</li>
<li><strong>Query</strong>:
<ul>
<li><strong>Vector Search</strong>: Find drugs with description similar to “ACE inhibitor”.</li>
<li><strong>Graph Filter</strong>: <code>MATCH (drug)-[:TREATS]-&gt;(c:Condition {name: 'Hypertension'})</code>.</li>
</ul>
</li>
</ol>
<h2 id="4-smart-manufacturing-production-optimization"><a class="header" href="#4-smart-manufacturing-production-optimization">4. Smart Manufacturing: Production Optimization</a></h2>
<p><strong>Source</strong>: <code>examples/smart_manufacturing_demo.rs</code></p>
<p>In a modern factory, thousands of variables must be balanced: machine speed, energy cost, and maintenance schedules.</p>
<p><strong>The Solution</strong>:
Samyama uses its built-in <strong>Jaya</strong> or <strong>GWO</strong> (Grey Wolf Optimizer) to adjust production rates across the graph. The objective is to maximize output while keeping total energy consumption below a specific threshold (the constraint).</p>
<h2 id="5-enterprise-soc-threat-hunting"><a class="header" href="#5-enterprise-soc-threat-hunting">5. Enterprise SOC: Threat Hunting</a></h2>
<p><strong>Source</strong>: <code>examples/enterprise_soc_demo.rs</code></p>
<p>Security Operations Centers (SOC) deal with millions of events (logins, file access, network traffic).</p>
<p><strong>The Solution</strong>:
By modeling logs as a graph, security analysts can run <strong>Pathfinding</strong> algorithms to trace the “Lateral Movement” of an attacker.</p>
<ul>
<li><strong>Graph RAG</strong>: Use vector search to find “unusual login behavior” semantically similar to known attack patterns.</li>
<li><strong>Graph Traversal</strong>: Instantly find all machines accessed by that user in the last 24 hours.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="the-future-of-graph-dbs"><a class="header" href="#the-future-of-graph-dbs">The Future of Graph DBs</a></h1>
<p>We have built a strong foundation, but the journey is just beginning. As we look toward version 1.0 and beyond, several frontier technologies will define the next generation of Samyama.</p>
<h2 id="1-time-travel-queries-temporal-graphs"><a class="header" href="#1-time-travel-queries-temporal-graphs">1. Time-Travel Queries (Temporal Graphs)</a></h2>
<p>Data is not static; it flows. Current graph databases only show the <em>current</em> state.</p>
<p>We plan to expose our internal MVCC versions to the user.
<strong>Goal</strong>: Allow queries like:</p>
<pre><code class="language-cypher">MATCH (p:Person)-[:KNOWS]-&gt;(f:Person)
WHERE p.name = 'Alice'
AT TIME '2023-01-01' -- Query the graph as it looked last year
RETURN f.name
</code></pre>
<p>This is invaluable for auditing, debugging, and historical analysis.</p>
<h2 id="2-graph-level-sharding"><a class="header" href="#2-graph-level-sharding">2. Graph-Level Sharding</a></h2>
<p>Currently, we shard by <strong>Tenant</strong>. This is perfect for SaaS but limits the size of a <em>single</em> graph to one machine’s capacity (vertical scaling).</p>
<p><strong>The Challenge</strong>: Partitioning a single graph across multiple machines is the “Holy Grail” of graph databases. It introduces the “Min-Cut” problem (minimizing edges that cross machines) to reduce network latency.</p>
<p><strong>The Plan</strong>: We are investigating <strong>METIS</strong> and streaming partitioning algorithms to intelligently distribute nodes based on community structure, ensuring that “friends stay together” on the same physical server.</p>
<h2 id="3-hardware-acceleration"><a class="header" href="#3-hardware-acceleration">3. Hardware Acceleration</a></h2>
<p>Rust gives us CPU efficiency, but for massive Vector Search and Graph Analytics, we need more power.</p>
<p><strong>GPU Acceleration</strong>:</p>
<ul>
<li>Using <code>wgpu</code> or <code>CUDA</code> to run the <code>samyama-graph-algorithms</code> (PageRank, Matrix Multiplication) directly on the GPU.</li>
<li>Offloading Vector HNSW index construction to the GPU.</li>
</ul>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Samyama started as a question: “Can we do better?”
The answer, we believe, is “Yes.”</p>
<p>By fusing the transactional integrity of RocksDB, the safety of Rust, and the semantic power of AI, we are building a database engine for the next decade of intelligent applications.</p>
<p>Thank you for exploring the architecture of Samyama with us.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="research-paper-samyama-overview"><a class="header" href="#research-paper-samyama-overview">Research Paper: Samyama Overview</a></h1>
<p>We have published a comprehensive research paper detailing the architecture and performance of Samyama Graph.</p>
<p><strong>Title</strong>: <em>Samyama: A Unified Distributed Graph-Vector Database with In-Database Optimization and Agentic Enrichment</em></p>
<h2 id="download-pdf"><a class="header" href="#download-pdf">Download PDF</a></h2>
<p>You can download the professional PDF version of this paper (arXiv-ready) from our GitHub Releases:
<a href="https://github.com/samyama-ai/samyama-graph-book/releases/latest/download/samyama_paper.pdf">Download Samyama Paper PDF</a></p>
<hr>
<h2 id="paper-abstract"><a class="header" href="#paper-abstract">Paper Abstract</a></h2>
<p>Modern data architectures are often fragmented, requiring separate systems for transactional graphs, vector embeddings, and analytical processing. We present <strong>Samyama</strong>, a high-performance, distributed graph-vector database written in Rust. Samyama unifies these workloads into a single engine by combining a RocksDB-backed persistent store with a versioned-arena MVCC model, a vectorized query executor, and a dedicated analytics engine using Compressed Sparse Row (CSR) structures. Notably, Samyama integrates 15+ metaheuristic optimization solvers directly into its query language and implements “Agentic Enrichment” for autonomous graph expansion. Our evaluation shows that Samyama achieves ingestion rates of 363k nodes/s and 1.5M edges/s, with query latencies improved by 4.7x through late materialization, making it a robust foundation for next-generation AI applications.</p>
<hr>
<h2 id="visualizations-via-paper-banana"><a class="header" href="#visualizations-via-paper-banana">Visualizations (via Paper-Banana)</a></h2>
<p>The paper includes several advanced illustrations generated by Google’s <strong>Paper-Banana</strong> agentic framework:</p>
<h3 id="1-unified-engine-architecture"><a class="header" href="#1-unified-engine-architecture">1. Unified Engine Architecture</a></h3>
<p>A high-level view of how the RESP protocol interacts with the Cypher parser, which in turn orchestrates the Vectorized Executor across the HNSW (Vector) and RocksDB (Graph) indices.
<img src="images/architecture.svg" alt="Samyama Architecture"></p>
<h3 id="2-the-optimization-frontier"><a class="header" href="#2-the-optimization-frontier">2. The Optimization Frontier</a></h3>
<p>A Pareto front chart illustrating how the NSGA-II solver identifies optimal trade-offs in multi-objective resource allocation directly on the graph.
<img src="images/pareto_front.svg" alt="Pareto Front"></p>
<h3 id="3-jit-knowledge-graph-expansion"><a class="header" href="#3-jit-knowledge-graph-expansion">3. JIT Knowledge Graph Expansion</a></h3>
<p>A sequence diagram showing the Agentic Enrichment loop: an event trigger initiates an LLM search which automatically creates new nodes and edges, “healing” the graph’s missing knowledge.
<img src="images/agentic_loop.svg" alt="Agentic Loop"></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
